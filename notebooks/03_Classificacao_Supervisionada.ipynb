{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96735c6f-a06d-47f3-8e95-71aaf658c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import funcy as fp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# Verificação de tipos\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Visualization / Presentation\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "# Bibliotecas e Funções para NLP\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "# Treinamento e Avaliação de Modelos\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Algoritmos adicionais para a criação de modelos\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Rastreamento de experimentos e modelos\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Recursos para visualização dos dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "# Carregar, além de atualizar frequentemente, código personalizado disponível em ../src\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "sys.path.append(os.path.abspath(os.path.pardir))\n",
    "from src import settings\n",
    "from src.utils.notebooks import display_side_by_side\n",
    "from src.utils.experiments import (set_dataset_split, \n",
    "                                   compute_multiclass_classification_metrics,\n",
    "                                   format_nested_parameters)\n",
    "from src.utils.text import clean_text\n",
    "from src.pipeline.wrappers import PreprocessingWrapper\n",
    "from src.pipeline.training_pipeline import (create_preprocessing_resources, \n",
    "                                            preprocess_features,\n",
    "                                            create_feature_matrix)\n",
    "\n",
    "# Configurações para a exibição de conteúdo do Pandas e das bibliotecas gráficas\n",
    "%matplotlib inline \n",
    "sns.set(rc={'figure.figsize':(25,10)})\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738b275-276d-4c62-a1bc-c4c327c26d04",
   "metadata": {},
   "source": [
    "# Importante: Este notebook está em estágio inicial de desenvolvimento\n",
    "\n",
    "TODO (ou devaneios):\n",
    " - Avaliar eficácia de pré-processar conteúdo textual;\n",
    " - Usar forma mais personalizada de preenchimento de valores ausentes;\n",
    " - Normalizar dados para fazer experimentação com modelos além do Catboost;\n",
    " - Padronizar e criar wrapper para persistir pipeline e modelo do experimento;\n",
    " - Apresentar métricas de avaliação por algoritmo e por algoritmo + categoria;\n",
    " - Avaliar qual estratégia seguir para validação: \n",
    "   - Cross-validation orientada por tempo ou amostras aleatórias (provavelmente o segundo, considerando que o conjunto de teste já está separado para a avaliação final)\n",
    " - Experimentações diversas:\n",
    "   - Avaliação de atributos;\n",
    "   - Uso de embeddings para titulo, tags, titulo + tags;\n",
    "   - Avaliar uso ou não de classes para balanceamento de categorias;\n",
    "   - Avaliar estratégias para se lidar com produtos repetidos e com mudanças ao longo do tempo;\n",
    "   - Analisar categorias com pior desempenho e verificar casos com erros;\n",
    "\n",
    "# Classificação de Produtos em Categorias\n",
    "\n",
    "Este notebook tem como propósito viabilizar os experimentos de criação de um classificador de produtos em categorias. Ainda que seja possível utilizar esse classificador para revisar produtos que possam estar categorizados de forma incorreta, é provável que exista um valor de utilização maior na possibilidade de classificar produtos recém cadastrados ou em processo de registro. Com isso, **não se deve esperar a disponibilidade de colunas relacionadas a busca ou às interações com os produtos**, como:\n",
    " - *query*\n",
    " - *search_page*\n",
    " - *position*\n",
    " - *view_counts*\n",
    " - *order_counts*\n",
    " \n",
    "Uma **possibilidade** de incorporar algumas dessas informações, como visualizações e pedidos, seria a **de utilizar uma estatística (e.g., média ou mediana) de produtos similares** que já tinham sido cadastrados antes do momento da criação do produto em questão. Por exemplo, fazer a média dos 50 produtos com título e preço mais semelhantes. De início, esses campos e possibilidades não serão exploradas, considerando que **pode não existir volume suficiente para trazer informações representativas de todos os produtos**. Pelo mesmo motivo, provavelmente **não serão utilizadas estatísticas sobre vendedores**.\n",
    "\n",
    "PS.: Se a qualidade do classificador não for satisfatória com as informações mínimas planejadas inicialmente, poderei apelar para as estratégias alternativas de incorporação dos demais campos. :0)\n",
    "\n",
    "Além dos atributos que provavelmente não estarão disponíveis no momento de uso do classificador, é preciso as variações das características dos produtos. Conforme a [Análise Exploratória](02_Analise_Exploratoria.ipynb), **preço (*price*), peso (*weight*), pronta entrega (*express_delivery*) e quantidade mínima (*minimum_quantity*) variam ao longo do tempo para um mesmo produto**. Assim, é preciso tomar uma decisão sobre como lidar com a repetição dos produtos nos dados:\n",
    " - Lidar apenas com produtos únicos:\n",
    "   - Descartar atributos que variam;\n",
    "   - ~Usar valor mais recente de cada atributo~ (não é viável sem data da busca);\n",
    "   - Calcular estatística sobre valores que variam;\n",
    " - Usar repetições dos produtos e  re-balancear o peso deles no treinamento do modelo; \n",
    " \n",
    " \n",
    "A utilização de produtos repetidos, com características que mudam com o tempo, pode ser interessante para trazer mais varidade de dados ao modelo, como uma aumentação natural. Caso seja preciso, pode-se tentar simular esse processo para produtos que não estejam repetidos.\n",
    "\n",
    "Com relação aos atributos textuais, a análise realizada indicou o maior potencial de uso de tags concatenadas e título. Além disso, foi possível notar que a similaridade entre o valor de um atributo textual e a média do mesmo atributo com relação a cada categoria funciona como um preditor razoável, semelhante a um KNN global. Pode-se explorar esse recurso como uma *feature* a mais no modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09162c4-7abf-4480-9625-36e8474a260b",
   "metadata": {},
   "source": [
    "## Configurações de Rastreamento de Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3303e24b-7090-4cd6-adb6-42040d841481",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = '01_SupervisedClassification'\n",
    "EXPERIMENT_RUN_NAME = f'Acceptable Set (Title and Tags Emb. and Sim. + Price)'\n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "# Se o experimento já não existir no MlFlow, criar um e recuperar ID\n",
    "experiment = mlflow_client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if not experiment:\n",
    "    mlflow_client.create_experiment(EXPERIMENT_NAME)\n",
    "    experiment = mlflow_client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "EXPERIMENT_ID = experiment.experiment_id\n",
    "del experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17d016-71af-4bb2-a4fa-2345b41d08c8",
   "metadata": {},
   "source": [
    "## Carregamento de Dados\n",
    "\n",
    "Para trabalhar o problema de classificação de produtos em categorias, é preciso utilizar o conjunto de dados de treinamento, dividido em  [01_Estruturacao.ipynb](01_Estruturacao.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fa9c6a-1e10-4499-9d3c-02a1c528a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_read = ['title', 'concatenated_tags', 'price', 'weight', 'express_delivery', 'minimum_quantity', 'category', 'creation_date']\n",
    "\n",
    "frame = (pd\n",
    "         .read_csv(os.path.join(settings.DATA_PATH, 'interim', 'training.csv'), usecols=columns_to_read)\n",
    "         .drop_duplicates()  # Manter mais de uma ocorrência de produto apenas se existir variação nos dados\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08265d67-d1ee-4510-916d-dd6027cbb8b2",
   "metadata": {},
   "source": [
    "Apesar de já existir uma separação de dados para teste, o ideal é mantê-la isolada até o momento da validação final. Assim, é preciso fazer uma nova separação para a experimentação com diferentes features. O período de separação será '2018-05', conforme utilizado em etapas anteriores de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185138d1-68df-49e8-940f-9df54d0bb788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                      <div style='display:block;float:left;padding:0 50px 0 0;text-align:center'>\n",
       "                         <h3>Treinamento</h3><br />\n",
       "                         <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Mandala Espírito Santo</td>\n",
       "      <td>Cartão de Visita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_tags</th>\n",
       "      <td>mandala mdf</td>\n",
       "      <td>cartao visita panfletos tag adesivos copos long drink canecas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation_date</th>\n",
       "      <td>2015-11-14 19:42:12</td>\n",
       "      <td>2018-04-04 20:55:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>171.89</td>\n",
       "      <td>77.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>express_delivery</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_quantity</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Decoração</td>\n",
       "      <td>Papel e Cia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>2015-11</td>\n",
       "      <td>2018-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "                      </div>\n",
       "                    \n",
       "                      <div style='display:block;float:left;padding:0 50px 0 0;text-align:center'>\n",
       "                         <h3>Validação</h3><br />\n",
       "                         <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Álbum de figurinhas dia dos pais</td>\n",
       "      <td>chaveiro dia dos pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_tags</th>\n",
       "      <td>albuns figurinhas pai lucas album fotos</td>\n",
       "      <td>dia pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation_date</th>\n",
       "      <td>2018-07-11 10:41:33</td>\n",
       "      <td>2018-07-04 12:47:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>49.97</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>208.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>express_delivery</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_quantity</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Lembrancinhas</td>\n",
       "      <td>Lembrancinhas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>2018-07</td>\n",
       "      <td>2018-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "                      </div>\n",
       "                    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cut_off_period = '2018-05'\n",
    "split_frame = set_dataset_split(frame, cut_off_period)\n",
    "\n",
    "training_frame = split_frame.loc[lambda f: f['group'] != 'test'].drop(columns=['group'])\n",
    "validation_frame = split_frame.loc[lambda f: f['group'] == 'test'].drop(columns=['group'])\n",
    "\n",
    "display_side_by_side([training_frame.head(2).T, validation_frame.head(2).T],\n",
    "                     ['Treinamento', 'Validação'],\n",
    "                     padding=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eee55c-2a78-4898-90c7-5a4dd8fd185e",
   "metadata": {},
   "source": [
    "## Codificar Labels\n",
    "\n",
    "O primeiro passo para realizar a experimentação é transformar as categorias, que são o rótulo da aprendizagem supervisionada. Para isso, cria-se um Label Encoder para estabelecer o padrão de codificação e permitir o reuso no momento de se fazer predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc18a13a-4bbd-4ab4-90b7-23ae379b4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(training_frame.category)\n",
    "\n",
    "y_training = label_encoder.transform(training_frame.category)\n",
    "y_validation = label_encoder.transform(validation_frame.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1914692-e6b5-4f4d-bf7a-8ca4e4e2076e",
   "metadata": {},
   "source": [
    "## Gerar Vetor de Características\n",
    "\n",
    "Conforme analisado em [Analise_Textual](02.1_Analise_Textual.ipynb), a primeira estratégia a ser explorada para trabalar com texto será utilizar *embeddings*. Com isso, espera-se contornar eventuais problemas com palavras fora do vocabulário e reduzir a dimensionalidade dos dados de treinamento. Adicionalmente, pode-se utilizar as informações de similaridade para fazer aumentação de dados textuais ou recuperar itens semelhantes para derivar outros valores (e.g., média de popularidade ou peso de de produtos semelhantes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadacfdd-7ce0-47b3-8dd0-0b0af8878232",
   "metadata": {},
   "source": [
    "No pipeline desenvolvido para experimentação, as transformações de *features* consideradas são:\n",
    " - **Embeddings de atributo textual**: Embeddings criados com o Word2Vect, com 300 dimensões, para representar atributos textuais (e.g., *title*, *concatenated_tags* e *query*);\n",
    " - **Similaridade entre os produtos de uma categoria**: Para cada categoria, calcula-se a similaridade entre a média dos *embeddings* de produtos da categoria e o item do conjunto de dados. Desse modo, pode-se sumarizar a medida dos *embeddings* sem utilizar 300 dimensões;\n",
    " - **Imputação de valores numéricos**: Criação de estatísticas que podem ser usadas para preencher dados numéricos ausentes -- importante para algoritmos que não têm algum mecanismo embutido para lidar com dados não preencidos. Essas estatísticas também podem ser utilizadas nos algoritmos não supervisionados, para atribuir um valor numérico ao produto simulado pela busca.\n",
    " \n",
    "Em todos os casos, é preciso ter o cuidado de não utilizar dados de avaliação, seja para validação ou teste, e ter uma estimativa incorreta da eficácia do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2850fb4-b1ad-4241-84ff-d83b8b21e128",
   "metadata": {},
   "source": [
    "A partir das funções criadas, pode-se criar o conjunto de elementos para o conjunto de treinamento (lista de categorias, embeddings dos produtos da categoria e dicionário de estatísticas de números). Posteriormente, esses recursos são utilizados para se pré-processar os conjuntos de dados de treinamento e de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194c0e64-4ef7-4851-9b34-d1a7fafaa229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Variáveis para controlar features\n",
    "text_columns_to_encode = ['title', 'concatenated_tags']\n",
    "numeric_columns_to_impute = ['price', 'weight', 'minimum_quantity']\n",
    "columns_to_copy = ['title', 'concatenated_tags', 'price', 'weight', 'minimum_quantity', 'category']\n",
    "similarity_features = ['title', 'concatenated_tags']\n",
    "\n",
    "# Pré-definição dos parâmetros para a função de limpeza de texto\n",
    "partial_clean_text_fn = partial(clean_text,\n",
    "                                unify_html_tags=False,\n",
    "                                unify_urls=False,\n",
    "                                trim_repeating_spaces=True,\n",
    "                                unify_hashtags=False,\n",
    "                                unify_mentions=False,\n",
    "                                unify_numbers=False,\n",
    "                                trim_repeating_letters=True)\n",
    "\n",
    "# Dicionários e recursos pré-computados para pré-processar features\n",
    "categories_list, category_embeddings_dict, numeric_stats_dict = create_preprocessing_resources(training_frame, \n",
    "                                                                                               text_columns_to_encode, \n",
    "                                                                                               numeric_columns_to_impute,\n",
    "                                                                                               partial_clean_text_fn)\n",
    "\n",
    "training_features_frame = preprocess_features(training_frame, \n",
    "                                             categories_list, \n",
    "                                             category_embeddings_dict, \n",
    "                                             numeric_stats_dict, \n",
    "                                             numeric_columns_to_impute, \n",
    "                                             text_columns_to_encode, \n",
    "                                             similarity_features,\n",
    "                                             partial_clean_text_fn)\n",
    "\n",
    "validation_features_frame = preprocess_features(validation_frame, \n",
    "                                                categories_list, \n",
    "                                                category_embeddings_dict, \n",
    "                                                numeric_stats_dict, \n",
    "                                                numeric_columns_to_impute,\n",
    "                                                text_columns_to_encode, \n",
    "                                                similarity_features,\n",
    "                                                partial_clean_text_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be328bae-b0db-48a9-a5cc-55d90860b708",
   "metadata": {},
   "source": [
    "As *features* criadas são exibidas a seguir para o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93a4b13-52fe-4cce-8c33-33f025b6e4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                      <div style='display:block;float:left;padding:0 5px 0 0;text-align:center'>\n",
       "                         <h3>Training Features</h3><br />\n",
       "                         <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Decoração</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>28.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_quantity</th>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_embedding</th>\n",
       "      <td>[-0.008050227, -0.008805177, 0.05007785, 0.052670166, -0.008375991, -0.08733791, 0.08137107, -0.047023904, -0.084045015, -0.114914, -0.015285425, -0.059007194, -0.01363755, -0.03596007, -0.037354697, -0.0053595444, 0.00013158719, 0.03680291, 0.01856682, -0.037185922, 0.012869673, 0.022040654, 0.04143815, 0.016028192, 0.008747943, -0.032603923, -0.04852895, -0.04586519, -0.005897246, 0.021057775, -0.03335154, -0.019760517, 0.05136871, -0.055092953, 0.017850965, 0.004519859, 0.029866127, -0.009489509, -0.032303855, -0.014851872, 0.018010547, 0.03169371, -0.024139842, 0.031021751, 0.0019302331, 0.049682837, -0.019554062, -0.042652845, -0.03941898, 0.02842769, -0.018753076, 0.11464983, -0.013627045, -0.03840479, 0.0011007756, -0.033052802, 0.06903171, -0.010560572, -0.11309786, 0.02618943, -0.0047901804, -0.07018264, -0.024092436, -0.079217196, 0.058002055, -0.00823592, -0.007264407, 4.9486447e-05, -0.0017880171, 0.078716084, -0.048081737, 0.016465433, 0.0044025565, 0.00875043, -0.025320936, 0.05028075, -0.02123936, -0.0045535928, -0.068652995, 0.025973309, 0.030222643, -0.0048072315, -0.024914764, 0.08709016, -0.033168092, 0.04838493, -0.016567186, 0.0012546282, -0.0029179032, 0.0023820798, 0.023580594, 0.008745926, -0.019628635, 0.099936746, 0.0519301, 0.08651835, -0.008959092, 0.022809967, 0.046600606, 0.09669861, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_tags_embedding</th>\n",
       "      <td>[-0.00096480176, 0.007755412, 0.055970505, -0.0019719256, -0.019442834, -0.06424611, -0.054305594, 0.016148726, -0.004429266, -0.011865409, 0.04533604, -0.02462662, -0.047025587, -0.06564285, -0.06875343, -0.076653786, 0.016040133, 0.055511396, -0.031783365, -0.04076623, 0.029454991, -0.06955534, 0.061893247, -0.010435247, 0.06066315, 0.007856408, -0.019301347, 0.001450764, 0.033383578, -0.005167395, 0.06935171, -0.02905846, 0.0120324325, -0.004273385, -0.024112757, -0.008683912, -0.018134523, -0.05764595, -0.041501626, 0.042161144, 0.09504889, 0.0640944, -0.03935487, -0.041973673, -0.018249096, 0.020226926, 0.043555792, -0.0001478903, -0.023421638, 0.018518515, -0.039450333, 0.08550055, -0.07622271, -0.08000244, 0.015642026, -0.09234807, 0.030455284, -0.024669042, -0.07880308, 0.07910919, -0.014150506, -0.026523495, -0.031564023, -0.043654054, 0.0664223, 0.0113486145, -0.0021935431, 0.07677206, 0.010576103, 0.0573722, -0.005085152, 0.025608867, -0.028094066, -0.028110277, -0.014501604, 0.021004904, 0.09872016, 0.020725429, -0.046325646, 0.032971967, 0.025173975, -0.029446376, 0.042171292, 0.03606745, 0.005886852, 0.062312253, 0.047403075, -0.026818678, 0.015970297, -0.009322384, -0.006390512, 0.03278854, -0.024431499, 0.032998025, 0.06951627, 0.009639874, -0.017778305, -0.008503529, 0.047630057, 0.09222877, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_title_bebê</th>\n",
       "      <td>0.485753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_title_bijuterias_e_jóias</th>\n",
       "      <td>0.466148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_title_decoração</th>\n",
       "      <td>0.506688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_title_lembrancinhas</th>\n",
       "      <td>0.499394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_title_outros</th>\n",
       "      <td>0.474644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_title_papel_e_cia</th>\n",
       "      <td>0.481328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_concatenated_tags_bebê</th>\n",
       "      <td>0.513799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_concatenated_tags_bijuterias_e_jóias</th>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_concatenated_tags_decoração</th>\n",
       "      <td>0.598231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_concatenated_tags_lembrancinhas</th>\n",
       "      <td>0.541212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_concatenated_tags_outros</th>\n",
       "      <td>0.553698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity_concatenated_tags_papel_e_cia</th>\n",
       "      <td>0.520818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "                      </div>\n",
       "                    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_side_by_side([training_features_frame.head(1).T], ['Training Features'])\n",
    "#display_side_by_side([validation_features_frame.head(1)], ['Validation Features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff49e6-7ddf-4667-8d66-9a40637f1b26",
   "metadata": {},
   "source": [
    "Com o conjunto de *feaures* pré-processadas, pode-se estabelecer as que serão utilizadas e submetê-las ao processo de criação de modelos para avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c432be5-2e54-4c31-ac4f-0f98d70a19a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Features</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Basic</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity_title_bebê\n",
      "similarity_title_bijuterias_e_jóias\n",
      "similarity_title_decoração\n",
      "similarity_title_lembrancinhas\n",
      "similarity_title_outros\n",
      "similarity_title_papel_e_cia\n",
      "similarity_concatenated_tags_bebê\n",
      "similarity_concatenated_tags_bijuterias_e_jóias\n",
      "similarity_concatenated_tags_decoração\n",
      "similarity_concatenated_tags_lembrancinhas\n",
      "similarity_concatenated_tags_outros\n",
      "similarity_concatenated_tags_papel_e_cia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Embeddings</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_embedding\n",
      "concatenated_tags_embedding\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Features Matrix</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training: (27130, 612) | X validation: (5599, 612)\n"
     ]
    }
   ],
   "source": [
    "#basic_features = ['price', 'weight', 'minimum_quantity']  + [item for item in training_features_frame.columns if item.startswith('similarity_')]\n",
    "basic_features = [item for item in training_features_frame.columns if item.startswith('similarity_')]\n",
    "embeddings_features = [item for item in training_features_frame.columns if item.endswith('_embedding')]\n",
    "\n",
    "display(HTML('<h3>Features</h3>'))\n",
    "display(HTML('<h4>Basic</h4>'))\n",
    "for item in basic_features:    \n",
    "    print(item)\n",
    "display(HTML('<h4>Embeddings</h4>'))\n",
    "for item in embeddings_features:    \n",
    "    print(item)\n",
    "\n",
    "X_training = create_feature_matrix(training_features_frame, basic_features, embeddings_features)\n",
    "X_validation = create_feature_matrix(validation_features_frame, basic_features, embeddings_features)\n",
    "\n",
    "display(HTML('<h4>Features Matrix</h4>'))\n",
    "print(f'X training: {X_training.shape} | X validation: {X_validation.shape}')\n",
    "\n",
    "pipeline_parameters = {\n",
    "    'basic_features': \", \".join(basic_features),\n",
    "    'embeddings_features': \", \".join(embeddings_features)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f30c58-3f12-4734-95e9-ee3f966528c6",
   "metadata": {},
   "source": [
    "## Empacotar Configurações, Recursos e Funções de Preprocessamento\n",
    "\n",
    "Para permitir a reprodução completa dos experimentos, os parâmetros utilizados para pré-processar os dados são empacotados em um *wrapper* para serem persistidos no MLFlow. Com isso, pode-se ter, para cada execução de algoritmo, quais as modificações feitas nos dados, o modelo criado e as métricas de avaliação registradas. \n",
    "\n",
    "Para este estudo de caso, a ideia é restaurar os parâmetros e funções de pré-processamento automaticamente e poder utilizá-los para inferência. Com isso, garante-se que não há diferença entre o que foi feito durante o treinamento do modelo e o uso em produção. A única ressalva com relação a essa forma de uso é que as funções de pré-processamento foram feitas de modo mais próximo de experimentação e não produtização. Para um modelo em produção, poderia ser mais interessante usar Spark para trabalhar com um volume maior, em modo de processamento de lote, ou usar estruturas de dados mais simples e eficientes para processamento (numpy, cupy ou mesmo listas e dicionários), para inferências individuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9edcd291-c020-495c-ab37-d3f2262dae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_wrapper = PreprocessingWrapper(partial_clean_fn=partial_clean_text_fn,\n",
    "                                             preprocess_fn=preprocess_features,\n",
    "                                             numeric_columns_to_impute=numeric_columns_to_impute,\n",
    "                                             text_columns_to_encode=text_columns_to_encode,\n",
    "                                             similarity_features=similarity_features,\n",
    "                                             categories=categories_list,\n",
    "                                             category_embeddings=category_embeddings_dict,\n",
    "                                             numeric_stats=numeric_stats_dict,\n",
    "                                             matrix_creation_fn=create_feature_matrix,\n",
    "                                             basic_features=basic_features,\n",
    "                                             embeddings_features=embeddings_features\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f7db8-3929-4b92-a02f-51d8285df63b",
   "metadata": {},
   "source": [
    "## Balanceamento de Classes\n",
    "\n",
    "Como há um desbalanceamento no número de registros de cada categoria, é interessante fazer um contra-balanceamento dos pesos para que exista uma proporcionalidade entre eles para o modelo. Assim, categorias com mais itens devem ter peso menor, enquanto categorias com menos itens possuem peso maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9777f3e-95c8-465e-9267-67f322c74a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                      <div style='display:block;float:left;padding:0 5px 0 0;text-align:center'>\n",
       "                         <h3>Distribuição de Categorias e Pesos</h3><br />\n",
       "                         <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>records</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bebê</td>\n",
       "      <td>5157</td>\n",
       "      <td>0.876802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bijuterias e Jóias</td>\n",
       "      <td>675</td>\n",
       "      <td>6.698765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decoração</td>\n",
       "      <td>6493</td>\n",
       "      <td>0.696391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lembrancinhas</td>\n",
       "      <td>12234</td>\n",
       "      <td>0.369598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outros</td>\n",
       "      <td>770</td>\n",
       "      <td>5.872294</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Papel e Cia</td>\n",
       "      <td>1801</td>\n",
       "      <td>2.510642</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "                      </div>\n",
       "                    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = len(training_frame)\n",
    "n_classes = len(categories_list)\n",
    "\n",
    "value_counts_frame = (training_frame\n",
    "                      [['category']]\n",
    "                      .assign(records=1)\n",
    "                      .groupby(['category'])\n",
    "                      .sum()\n",
    "                      .reset_index()                      \n",
    "                      .assign(weight=lambda f: f['records'].apply(lambda r: n_samples / (n_classes * r)))\n",
    "                      .assign(label=lambda f: label_encoder.transform(f['category']))\n",
    "                     )\n",
    "display_side_by_side([value_counts_frame], ['Distribuição de Categorias e Pesos'])\n",
    "\n",
    "class_weights = {item.label: item.weight for item in value_counts_frame[['label', 'weight']].itertuples(index=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea58e3c-e913-498a-9639-0a768efcd528",
   "metadata": {},
   "source": [
    "A seguir, tem-se a estrutura de exploração de algoritmos e parâmetros que podem ser utilizados para criar modelos de classificação. Com o uso do MLFlow, cada experimento pode ser registrado para que o histórico sirva para avaliar as mudanças que foram mais eficazes.\n",
    "\n",
    "Para fazer a experimentação, consideraria algumas opções:\n",
    " - **Catboost**: uma alternativa entre as versões de gradient boosting --  como XBoost e LightGBM -- a partir de árvores de decisão. Oferece recursos para tratamento de variáveis categóricas e textuais, tem bom ajuste automático de hiperparâmetros (considerando os dados) e desempenho, com suporte a GPU, além de suportar dados não preenchidos.\n",
    " - **Redes Neurais**: apesar de exigir tratamentos adicionais nos dados (normalização e imputação de valores ausentes), tende a oferecer bom desempenho no cenário atual, especialmente com o uso de *embeddings*.\n",
    " - **KNN**: Ainda que também possa precisar de tratamentos de dados pelo uso de medidas de similaridade e de não esperar o melhor desempenho, é conveniente pelo uso de *embeddings* e já tem um potencial mínimo aferido pelas experimentações em [Análise Textual](02.1_Analise_Exploratoria.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c445d-4e41-4b9c-adcf-26737040d744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b94c5574bc4e8e9439e56da8f6dd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "models_parameters = {    \n",
    "    'MLP': {'activation':'tanh', 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes':(200, 200)},\n",
    "    'CB': {'loss_function': 'MultiClass', 'classes_count': num_classes, 'iterations': 200, 'save_snapshot': False, 'verbose': False, 'class_weights': class_weights},\n",
    "}\n",
    "\n",
    "fit_parameters = {    \n",
    "    'MLP': {},\n",
    "    'CB': {},\n",
    "}\n",
    "\n",
    "models_to_train = {\n",
    "    'MLP': MLPClassifier,\n",
    "    'CB': CatBoostClassifier\n",
    "}\n",
    "\n",
    "training_repetitions = 3\n",
    "iterations_tracking = []\n",
    "trained_models = []\n",
    "validation_scores = []\n",
    "\n",
    "with mlflow.start_run(run_name=EXPERIMENT_RUN_NAME, experiment_id=EXPERIMENT_ID) as main_run:\n",
    "    # A cada execução limpa o diretório de artefatos para gravar novos, a serem salvos no MLflow\n",
    "    if os.path.exists(settings.LOGS_ARTIFACTS_PATH):\n",
    "        shutil.rmtree(settings.LOGS_ARTIFACTS_PATH)\n",
    "    os.makedirs(settings.LOGS_ARTIFACTS_PATH) \n",
    "\n",
    "    mlflow.log_param('training_repetitions', training_repetitions)\n",
    "\n",
    "    # Registra parâmetros de limpeza de texto\n",
    "    simple_partial_clean_text_params, complex_partial_clean_text_params = format_nested_parameters(partial_clean_text_fn.keywords, 'clean_text')\n",
    "    mlflow.log_params(simple_partial_clean_text_params)\n",
    "\n",
    "    simple_pipeline_params, complex_pipeline_params = format_nested_parameters(pipeline_parameters, 'pipeline')\n",
    "    mlflow.log_params(simple_pipeline_params)\n",
    "\n",
    "    # Registra as dimensões dos vetores de treinamento e validação\n",
    "    mlflow.log_param('X_training', X_training.shape)\n",
    "    mlflow.log_param('X_validation', X_validation.shape)\n",
    "\n",
    "    for ix in tqdm(range(training_repetitions)):\n",
    "        # Embabaralha os dados de treinamento para a iteração\n",
    "        iteration_index = np.arange(X_training.shape[0])\n",
    "        np.random.shuffle(iteration_index)\n",
    "\n",
    "        for model_name, model_class in models_to_train.items():\n",
    "\n",
    "            # Registra a execução aninhada do algoritmo\n",
    "            with mlflow.start_run(run_name=f'01_{ix}_{EXPERIMENT_RUN_NAME}_{model_name}', experiment_id=EXPERIMENT_ID, nested=True) as nested_run:\n",
    "                start_time = time.time()\n",
    "                model = model_class(**models_parameters.get(model_name, {}))\n",
    "                model.fit(X_training[iteration_index], y_training[iteration_index])\n",
    "                mlflow.log_metric('training_time', time.time() - start_time)\n",
    "\n",
    "                trained_models.append((model_name, ix, model)) \n",
    "                preds = model.predict(X_validation)\n",
    "\n",
    "                eval_metrics = compute_multiclass_classification_metrics(y_validation, preds.round(), average='macro')\n",
    "\n",
    "                iteration_tracking = {**{'Algorithm': model_name,\n",
    "                                         'Iteration': ix}, \n",
    "                                      **eval_metrics}\n",
    "                iterations_tracking.append(iteration_tracking)\n",
    "\n",
    "                validation_scores.append((model_name, ix, eval_metrics['f1']))\n",
    "\n",
    "                mlflow.log_param('model_name', model_name)\n",
    "                mlflow.log_params(models_parameters.get(model_name, {}))\n",
    "                mlflow.sklearn.log_model(model, \"model\")\n",
    "                for key, value in eval_metrics.items():\n",
    "                    mlflow.log_metric(key, np.mean(value))\n",
    "\n",
    "                # Salva o modelo criado\n",
    "                signature = infer_signature(X_training, preds)\n",
    "                mlflow.sklearn.log_model(model, model_name, signature=signature)\n",
    "\n",
    "    # Métricas de avaliação individual\n",
    "    evaluation_frame = pd.DataFrame(iterations_tracking)\n",
    "    evaluation_frame.to_csv(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs.csv'))\n",
    "    evaluation_frame.to_html(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs.html'))\n",
    "\n",
    "    # Sumarização das métricas de várias execuções de um mesmo algoritmo    \n",
    "    evaluation_summary_frame = (evaluation_frame\n",
    "                                [['Algorithm', 'acc', 'precision', 'recall', 'f1']]\n",
    "                                .groupby('Algorithm')\n",
    "                                .agg([np.mean, np.std])\n",
    "                               )\n",
    "\n",
    "    for item in evaluation_summary_frame.itertuples():\n",
    "        mlflow.log_metric(item.Index, item._7)\n",
    "\n",
    "    best_result_index = evaluation_summary_frame[('f1', 'mean')].argmax()\n",
    "    for metric in ['acc', 'precision', 'recall', 'f1']:\n",
    "        mlflow.log_metric(metric, evaluation_summary_frame.iloc[best_result_index][(metric, \"mean\")])\n",
    "\n",
    "    evaluation_summary_frame.to_csv(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs_summary.csv'))\n",
    "    evaluation_summary_frame.to_html(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs_summary.html'))\n",
    "    \n",
    "    for param_name, param_value in {**complex_partial_clean_text_params, **complex_pipeline_params}.items():\n",
    "        with open(f'{settings.LOGS_ARTIFACTS_PATH}/{param_name}.txt', 'w') as file:\n",
    "            file.write(param_value)\n",
    "\n",
    "    # Armazena o wrapper de pré-processamento junto com os dados do experimento\n",
    "    preprocessing_model_path = os.path.join(settings.LOGS_ARTIFACTS_PATH, 'preprocessing_model')\n",
    "    mlflow.pyfunc.save_model(path=preprocessing_model_path, python_model=preprocessing_wrapper)\n",
    "    \n",
    "    # Salva o LabelEncoder\n",
    "    signature = infer_signature(training_frame.category, preds)\n",
    "    mlflow.sklearn.log_model(label_encoder, 'label_encoder', signature=signature)\n",
    "\n",
    "    mlflow.log_artifact(settings.LOGS_ARTIFACTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e341ecc-a274-4bf7-8b92-0300f6264963",
   "metadata": {},
   "source": [
    "## Resultados do Experimento\n",
    "\n",
    "Esta experimentação básica está persistida apenas como exemplo. Nesta avaliação, é provável que o algoritmo de MLP tenha vantagem pela ausência de opção de balanceamento de classes. Uma forma de contornar o problema sem exigir muitas modificações é fazer o balanceamento por reamostragem, proporcional aos pesos calculados. No entanto, essa estratégia tende a aumentar o volume de dados e, como consequência, a utilização de recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c627c7e-8c63-444f-b89b-ea4167c584a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_side_by_side([evaluation_summary_frame], ['Resumo das Execuções'])\n",
    "\n",
    "for column in ['f1']:\n",
    "    plt.figure(figsize=(20,10))\n",
    "    ax = sns.boxplot(x=\"Algorithm\", y=column, data=evaluation_frame)\n",
    "    ax.set_title(f'Avaliação de {column.capitalize()} para {training_repetitions} treinamentos', fontdict={'fontsize':25});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
