{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96735c6f-a06d-47f3-8e95-71aaf658c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import funcy as fp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# Verificação de tipos\n",
    "from typing import List\n",
    "\n",
    "# Visualization / Presentation\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "# Bibliotecas e Funções para NLP\n",
    "import re\n",
    "import fasttext\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "# Treinamento e Avaliação de Modelos\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Algoritmos adicionais para a criação de modelos\n",
    "from lightgbm.sklearn import LGBMModel\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Rastreamento de experimentos e modelos\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Recursos para visualização dos dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "# Carregar código personalizado disponível em ../src\n",
    "sys.path.append(os.path.abspath(os.path.pardir))\n",
    "from src import settings\n",
    "from src.utils.notebooks import display_side_by_side\n",
    "from src.utils.experiments import set_dataset_split, compute_multiclass_classification_metrics\n",
    "\n",
    "# Configurações para a exibição de conteúdo do Pandas e das bibliotecas gráficas\n",
    "%matplotlib inline \n",
    "sns.set(rc={'figure.figsize':(25,10)})\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3303e24b-7090-4cd6-adb6-42040d841481",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = '01_ShallowModels'\n",
    "EXPERIMENT_RUN_NAME = f'Structuring'\n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "experiment = mlflow_client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if not experiment:\n",
    "    mlflow_client.create_experiment(EXPERIMENT_NAME)\n",
    "    experiment = mlflow_client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "EXPERIMENT_ID = experiment.experiment_id\n",
    "del experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738b275-276d-4c62-a1bc-c4c327c26d04",
   "metadata": {},
   "source": [
    "# Importante: Este notebook está em estágio inicial de desenvolvimento\n",
    "\n",
    "TODO (ou devaneios):\n",
    " - Criar mecanismo para preencher valores ausentes;\n",
    " - Normalizar dados para fazer experimentação com modelos além do Catboost;\n",
    " - Padronizar e criar wrapper para persistir pipeline e modelo do experimento;\n",
    " - Apresentar métricas de avaliação por algoritmo e por algoritmo + categoria;\n",
    " - Avaliar qual estratégia seguir para validação: \n",
    "   - Cross-validation orientada por tempo ou amostras aleatórias (provavelmente o segundo, considerando que o conjunto de teste já está separado para a avaliação final)\n",
    " - Experimentações diversas:\n",
    "   - Avaliação de atributos;\n",
    "   - Uso de embeddings para titulo, tags, titulo + tags;\n",
    "   - Avaliar uso ou não de classes para balanceamento de categorias;\n",
    "   - Avaliar estratégias para se lidar com produtos repetidos e com mudanças ao longo do tempo;\n",
    "   - Analisar categorias com pior desempenho e verificar casos com erros;\n",
    "\n",
    "# Classificação de Produtos em Categorias\n",
    "\n",
    "Este notebook tem como propósito viabilizar os experimentos de criação de um classificador de produtos em categorias. Ainda que seja possível utilizar esse classificador para revisar produtos que possam estar categorizados de forma incorreta, é provável que exista um valor de utilização maior na possibilidade de classificar produtos recém cadastrados ou em processo de registro. Com isso, **não se deve esperar a disponibilidade de colunas relacionadas a busca ou às interações com os produtos**, como:\n",
    " - *query*\n",
    " - *search_page*\n",
    " - *position*\n",
    " - *view_counts*\n",
    " - *order_counts*\n",
    " \n",
    "Uma **possibilidade** de incorporar algumas dessas informações, como visualizações e pedidos, seria a **de utilizar uma estatística (e.g., média ou mediana) de produtos similares** que já tinham sido cadastrados antes do momento da criação do produto em questão. Por exemplo, fazer a média dos 50 produtos com título e preço mais semelhantes. De início, esses campos e possibilidades não serão exploradas, considerando que **pode não existir volume suficiente para trazer informações representativas de todos os produtos**. Pelo mesmo motivo, provavelmente **não serão utilizadas estatísticas sobre vendedores**.\n",
    "\n",
    "PS.: Se a qualidade do classificador não for satisfatória com as informações mínimas planejadas inicialmente, poderei apelar para as estratégias alternativas de incorporação dos demais campos. :0)\n",
    "\n",
    "Além dos atributos que provavelmente não estarão disponíveis no momento de uso do classificador, é preciso as variações das características dos produtos. Conforme a [Análise Exploratória](02_Analise_Exploratoria.ipynb), **preço (*price*), peso (*weight*), pronta entrega (*express_delivery*) e quantidade mínima (*minimum_quantity*) variam ao longo do tempo para um mesmo produto**. Assim, é preciso tomar uma decisão sobre como lidar com a repetição dos produtos nos dados:\n",
    " - Lidar apenas com produtos únicos:\n",
    "   - Descartar atributos que variam;\n",
    "   - ~Usar valor mais recente de cada atributo~ (não é viável sem data da busca);\n",
    "   - Calcular estatística sobre valores que variam;\n",
    " - Usar repetições dos produtos e  re-balancear o peso deles no treinamento do modelo; \n",
    " \n",
    "A utilização de produtos repetidos, com características que mudam com o tempo, pode ser interessante para trazer mais varidade de dados ao modelo, como uma aumentação natural. Caso seja preciso, pode-se tentar simular\n",
    " \n",
    "Essas questões podem ser avaliadas de modo relativamente rápido entre as experimentações.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17d016-71af-4bb2-a4fa-2345b41d08c8",
   "metadata": {},
   "source": [
    "### Carregamento de Dados\n",
    "\n",
    "Para trabalhar o problema de classificação de produtos em categorias, é preciso utilizar o conjunto de dados de treinamento, dividido em  [01_Estruturacao.ipynb](01_Estruturacao.ipynb). Ainda que \n",
    ", recuperar apenas as informações que podem ser us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fa9c6a-1e10-4499-9d3c-02a1c528a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_read = ['title', 'concatenated_tags', 'price', 'weight', 'express_delivery', 'minimum_quantity', 'category', 'creation_date']\n",
    "\n",
    "frame = (pd\n",
    "         .read_csv(os.path.join(settings.DATA_PATH, 'interim', 'training.csv'), usecols=columns_to_read)\n",
    "         .drop_duplicates()  # Manter mais de uma ocorrência de produto apenas se existir variação nos dados\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185138d1-68df-49e8-940f-9df54d0bb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_period = '2018-05'\n",
    "split_frame = set_dataset_split(frame, cut_off_period)\n",
    "\n",
    "training_frame = split_frame.loc[lambda f: f['group'] != 'test'].drop(columns=['group'])\n",
    "validation_frame = split_frame.loc[lambda f: f['group'] == 'test'].drop(columns=['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6069a21e-b609-42b2-b10d-e92e852a66d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                      <div style='display:block;float:left;padding:0 50px 0 0;text-align:center'>\n",
       "                         <h3>Treinamento</h3><br />\n",
       "                         <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Mandala Espírito Santo</td>\n",
       "      <td>Cartão de Visita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_tags</th>\n",
       "      <td>mandala mdf</td>\n",
       "      <td>cartao visita panfletos tag adesivos copos long drink canecas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation_date</th>\n",
       "      <td>2015-11-14 19:42:12</td>\n",
       "      <td>2018-04-04 20:55:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>171.89</td>\n",
       "      <td>77.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>express_delivery</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_quantity</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Decoração</td>\n",
       "      <td>Papel e Cia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>2015-11</td>\n",
       "      <td>2018-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "                      </div>\n",
       "                    \n",
       "                      <div style='display:block;float:left;padding:0 50px 0 0;text-align:center'>\n",
       "                         <h3>Validação</h3><br />\n",
       "                         <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Álbum de figurinhas dia dos pais</td>\n",
       "      <td>chaveiro dia dos pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenated_tags</th>\n",
       "      <td>albuns figurinhas pai lucas album fotos</td>\n",
       "      <td>dia pais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation_date</th>\n",
       "      <td>2018-07-11 10:41:33</td>\n",
       "      <td>2018-07-04 12:47:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>49.97</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>208.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>express_delivery</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_quantity</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Lembrancinhas</td>\n",
       "      <td>Lembrancinhas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>2018-07</td>\n",
       "      <td>2018-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "                      </div>\n",
       "                    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_side_by_side([training_frame.head(2).T, validation_frame.head(2).T],\n",
    "                     ['Treinamento', 'Validação'],\n",
    "                     padding=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1914692-e6b5-4f4d-bf7a-8ca4e4e2076e",
   "metadata": {},
   "source": [
    "### Gerar Vetor de Características\n",
    "\n",
    "Conforme analisado em [Analise_Textual](02.1_Analise_Textual.ipynb), a primeira estratégia a ser explorada para trabalar com texto será utilizar *embeddings*. Com isso, espera-se contornar eventuais problemas com palavras fora do vocabulário e reduzir a dimensionalidade dos dados de treinamento. Adicionalmente, pode-se utilizar as informações de similaridade para fazer aumentação de dados textuais ou recuperar itens semelhantes para derivar outros valores (e.g., média de popularidade ou peso de de produtos semelhantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14902171-edcc-445a-8aa1-45b8d1eaaca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft_model = fasttext.load_model(os.path.join(settings.MODELS_PATH, 'cc.pt.300.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eee55c-2a78-4898-90c7-5a4dd8fd185e",
   "metadata": {},
   "source": [
    "Criar codificador das categorias dos produtos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc18a13a-4bbd-4ab4-90b7-23ae379b4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(training_frame.category)\n",
    "\n",
    "y_training = label_encoder.transform(training_frame.category)\n",
    "y_validation = label_encoder.transform(validation_frame.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadacfdd-7ce0-47b3-8dd0-0b0af8878232",
   "metadata": {},
   "source": [
    "Iniciar organização do processamento das caracerísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d51ea03-002d-4582-b989-4c564394c34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training: (27130, 303) | X validation: (5599, 303)\n"
     ]
    }
   ],
   "source": [
    "def create_feature_vector(base_frame: pd.DataFrame, feature_columns: List[str], columns_to_encode_as_embeddings: List[str]) -> np.array:\n",
    "    \"Função para processar gerar embeddings, criar processar demais features e criar vetor final para treino/inferência.\"\n",
    "    embeddings_columns = []\n",
    "    basic_columns = []\n",
    "\n",
    "    for column in columns_to_encode_as_embeddings:\n",
    "        embedding_column = np.stack(base_frame[column]\n",
    "                                    .str\n",
    "                                    .lower()\n",
    "                                    .apply(ft_model.get_sentence_vector)\n",
    "                                    .to_numpy(), axis=0)\n",
    "        embeddings_columns.append(embedding_column)\n",
    "\n",
    "    basic_columns = [np.expand_dims(base_frame[column].to_numpy(), axis=1) \n",
    "                     for column in feature_columns]\n",
    "\n",
    "    return np.concatenate(embeddings_columns + basic_columns, axis=1)\n",
    "\n",
    "feature_columns = ['price', 'weight', 'express_delivery']\n",
    "columns_to_encode_as_embeddings = ['title']\n",
    "\n",
    "X_training = create_feature_vector(training_frame, feature_columns, columns_to_encode_as_embeddings)\n",
    "X_validation = create_feature_vector(validation_frame, feature_columns, columns_to_encode_as_embeddings)\n",
    "\n",
    "print(f'X training: {X_training.shape} | X validation: {X_validation.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f7db8-3929-4b92-a02f-51d8285df63b",
   "metadata": {},
   "source": [
    "Como há um desbalanceamento no número de registros de cada categoria, é interessante fazer um contra-balanceamento dos pesos para que exista uma proporcionalidade entre eles para o modelo. Assim, categorias com mais itens devem ter peso menor, enquanto categorias com menos itens possuem peso maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9777f3e-95c8-465e-9267-67f322c74a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                      <div style='display:block;float:left;padding:0 5px 0 0;text-align:center'>\n",
       "                         <h3>Distribuição de Categorias e Pesos</h3><br />\n",
       "                         <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>records</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bebê</td>\n",
       "      <td>5157</td>\n",
       "      <td>0.876802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bijuterias e Jóias</td>\n",
       "      <td>675</td>\n",
       "      <td>6.698765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decoração</td>\n",
       "      <td>6493</td>\n",
       "      <td>0.696391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lembrancinhas</td>\n",
       "      <td>12234</td>\n",
       "      <td>0.369598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outros</td>\n",
       "      <td>770</td>\n",
       "      <td>5.872294</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Papel e Cia</td>\n",
       "      <td>1801</td>\n",
       "      <td>2.510642</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "                      </div>\n",
       "                    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = len(training_frame)\n",
    "n_classes = len(training_frame['category'].unique())\n",
    "\n",
    "value_counts_frame = (training_frame\n",
    "                      [['category']]\n",
    "                      .assign(records=1)\n",
    "                      .groupby(['category'])\n",
    "                      .sum()\n",
    "                      .reset_index()                      \n",
    "                      .assign(weight=lambda f: f['records'].apply(lambda r: n_samples / (n_classes * r)))\n",
    "                      .assign(label=lambda f: label_encoder.transform(f['category']))\n",
    "                     )\n",
    "display_side_by_side([value_counts_frame], ['Distribuição de Categorias e Pesos'])\n",
    "\n",
    "class_weights = {item.label: item.weight for item in value_counts_frame[['label', 'weight']].itertuples(index=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea58e3c-e913-498a-9639-0a768efcd528",
   "metadata": {},
   "source": [
    "A seguir, tem-se a estrutura de exploração de algoritmos e parâmetros que podem ser utilizados para criar modelos de classificação. Com o uso do MLFlow, cada experimento pode ser registrado para que o histórico sirva para avaliar as mudanças que foram mais eficazes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953c445d-4e41-4b9c-adcf-26737040d744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f275f9e8c75c483aa489949f354d61b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "models_parameters = {    \n",
    "    'MLP': {'activation':'tanh', 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'alpha': 0.001, 'early_stopping': True, 'hidden_layer_sizes':(200, 200)},\n",
    "    'LGB': {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': num_classes, 'verbosity': -1, 'feature_pre_filter': False, 'lambda_l1': 0.5955392344062058, \n",
    "            'lambda_l2': 1.1394638571883556e-08, 'num_leaves': 35, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 5, \n",
    "            'num_iterations': 200, 'early_stopping_round': None, 'random_state': None, 'class_weight': 'balanced'},\n",
    "    'CB': {'loss_function': 'MultiClass', 'classes_count': num_classes, 'iterations': 200, 'save_snapshot': False, 'verbose': False, 'class_weights': class_weights},\n",
    "    'MultinomialNB': {'alpha': 0.125},\n",
    "}\n",
    "\n",
    "fit_parameters = {    \n",
    "    'MLP': {},\n",
    "    'LGB': {},\n",
    "    'CB': {},\n",
    "    'MultinomialNB': {},\n",
    "}\n",
    "\n",
    "models_to_train = {\n",
    "    #'MLP': MLPClassifier,\n",
    "    #'LGB': LGBMModel,\n",
    "    'CB': CatBoostClassifier,\n",
    "    #'MultinomialNB': MultinomialNB,\n",
    "}\n",
    "\n",
    "training_repetitions = 3\n",
    "iterations_tracking = []\n",
    "trained_models = []\n",
    "validation_scores = []\n",
    "\n",
    "with mlflow.start_run(run_name=EXPERIMENT_RUN_NAME, experiment_id=EXPERIMENT_ID) as main_run:\n",
    "    # A cada execução limpa o diretório de artefatos para gravar novos, a serem salvos no MLflow\n",
    "    if os.path.exists(settings.LOGS_ARTIFACTS_PATH):\n",
    "        shutil.rmtree(settings.LOGS_ARTIFACTS_PATH)\n",
    "    os.makedirs(settings.LOGS_ARTIFACTS_PATH) \n",
    "\n",
    "    mlflow.log_param('training_repetitions', training_repetitions)\n",
    "\n",
    "    #mlflow.log_param('main_token_processors', ', '.join([item.__name__ for item in main_token_processors]))\n",
    "    #mlflow.log_param('extra_token_processors', ', '.join([item.__name__ for item in extra_token_processors]))\n",
    "\n",
    "    #mlflow.log_param('main_sentence_processors', ', '.join([item.__name__ for item in main_sentence_processors]))\n",
    "    #mlflow.log_param('extra_sentence_processors', ', '.join([item.__name__ for item in extra_sentence_processors]))\n",
    "\n",
    "    #simple_partial_clean_text_params, complex_partial_clean_text_params = format_nested_parameters(partial_clean_text.keywords, 'clean_text')\n",
    "    #mlflow.log_params(simple_partial_clean_text_params)\n",
    "\n",
    "    #simple_pipeline_params, complex_pipeline_params = format_nested_parameters(pipeline_parameters, 'pipeline')\n",
    "    #mlflow.log_params(simple_pipeline_params)\n",
    "\n",
    "    mlflow.log_param('X_training', X_training.shape)\n",
    "    mlflow.log_param('X_validation', X_validation.shape)\n",
    "\n",
    "    for ix in tqdm(range(training_repetitions)):\n",
    "        iteration_index = np.arange(X_training.shape[0])\n",
    "        np.random.shuffle(iteration_index)\n",
    "\n",
    "        for model_name, model_class in models_to_train.items():\n",
    "\n",
    "            with mlflow.start_run(run_name=f'01_{ix}_{EXPERIMENT_RUN_NAME}_{model_name}', experiment_id=EXPERIMENT_ID, nested=True) as nested_run:\n",
    "                start_time = time.time()\n",
    "                model = model_class(**models_parameters.get(model_name, {}))\n",
    "                model.fit(X_training[iteration_index], y_training[iteration_index])\n",
    "                mlflow.log_metric('training_time', time.time() - start_time)\n",
    "\n",
    "                trained_models.append((model_name, ix, model)) \n",
    "                preds = model.predict(X_validation)\n",
    "\n",
    "                eval_metrics = compute_multiclass_classification_metrics(y_validation, preds.round())\n",
    "                iteration_tracking = {**{'Algorithm': model_name,\n",
    "                                         'Iteration': ix}, \n",
    "                                      **eval_metrics}\n",
    "                iterations_tracking.append(iteration_tracking)\n",
    "\n",
    "                validation_scores.append((model_name, ix, eval_metrics['f1']))\n",
    "\n",
    "                mlflow.log_param('model_name', model_name)\n",
    "                mlflow.log_params(models_parameters.get(model_name, {}))\n",
    "                mlflow.sklearn.log_model(model, \"model\")\n",
    "                for key, value in eval_metrics.items():\n",
    "                    mlflow.log_metric(key, np.mean(value))\n",
    "                    \n",
    "                # Save model\n",
    "                signature = infer_signature(X_training, preds)\n",
    "                mlflow.sklearn.log_model(model, model_name, signature=signature)\n",
    "\n",
    "    # Métricas de avaliação individual\n",
    "    evaluation_frame = pd.DataFrame(iterations_tracking)\n",
    "    evaluation_frame.to_csv(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs.csv'))\n",
    "    evaluation_frame.to_html(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs.html'))\n",
    "\n",
    "    # Sumarização das métricas de várias execuções de um mesmo algoritmo\n",
    "    evaluation_summary_frame = (evaluation_frame\n",
    "                                [['Algorithm', 'acc', 'precision', 'recall', 'f1']]\n",
    "                                .assign(**{item: lambda f: f[item].apply(np.mean) \n",
    "                                           for item in ['precision', 'recall', 'f1']})\n",
    "                                .groupby('Algorithm')\n",
    "                                .agg([np.mean, np.std])\n",
    "                               )\n",
    "\n",
    "    for item in evaluation_summary_frame.itertuples():\n",
    "        mlflow.log_metric(item.Index, item._6)\n",
    "\n",
    "    best_result_index = evaluation_summary_frame[('f1', 'mean')].argmax()\n",
    "    for metric in ['acc', 'precision', 'recall', 'f1']:\n",
    "        mlflow.log_metric(metric, evaluation_summary_frame.iloc[best_result_index][(metric, \"mean\")])\n",
    "\n",
    "    evaluation_summary_frame.to_csv(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs_summary.csv'))\n",
    "    evaluation_summary_frame.to_html(os.path.join(settings.LOGS_ARTIFACTS_PATH, 'experiment_runs_summary.html'))\n",
    "\n",
    "    #for param_name, param_value in {**complex_partial_clean_text_params, **complex_pipeline_params}.items():\n",
    "    #    with open(f'{settings.LOGS_ARTIFACTS_PATH}/{param_name}.txt', 'w') as file:\n",
    "    #        file.write(param_value)\n",
    "            \n",
    "    # Store the preprocessing resources\n",
    "    #preprocessing_model_path = os.path.join(settings.LOGS_ARTIFACTS_PATH, 'preprocessing_model')\n",
    "    #mlflow.pyfunc.save_model(path=preprocessing_model_path, python_model=preprocessing_wrapper)\n",
    "\n",
    "    mlflow.log_artifact(settings.LOGS_ARTIFACTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0380edee-a863-43a5-8c49-6353cc20f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">acc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CB</th>\n",
       "      <td>0.839197</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.773503</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.773503</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.773503</td>\n",
       "      <td>0.008579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc           precision              recall            \\\n",
       "               mean       std      mean       std      mean       std   \n",
       "Algorithm                                                               \n",
       "CB         0.839197  0.002728  0.773503  0.008579  0.773503  0.008579   \n",
       "\n",
       "                 f1            \n",
       "               mean       std  \n",
       "Algorithm                      \n",
       "CB         0.773503  0.008579  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_summary_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c627c7e-8c63-444f-b89b-ea4167c584a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
